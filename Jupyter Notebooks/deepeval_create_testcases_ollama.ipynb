{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dc1be-f42f-4a02-a1b7-cc8aa2ae3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = \"HUGGINGFACE TOKEN HERE\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=hf_token\n",
    "os.environ[\"HF_TOKEN\"]=hf_token\n",
    "os.environ['HF_HOME'] = 'YOUR_HOME_DIR/.cache/huggingface/'\n",
    "os.environ['TRANSFOMERS_CACHE'] = 'YOUR_HOME_DIR/.cache/huggingface/'\n",
    "import transformers\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf88d1-021f-45c2-b792-b88da9d704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = HuggingFaceEmbedding(model_name=\"abhinand/MedEmbed-large-v0.1\")\n",
    "\n",
    "Settings.embed_model = EMBED_MODEL\n",
    "embed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c287e8-44f3-4a07-ba5a-698cd45795d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD VECTORE INDEX FROM DISK (NOT WORKING PROPERLY)\n",
    "\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, load_index_from_storage\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from docling.document_converter import DocumentConverter\n",
    "from llama_index.node_parser.docling import DoclingNodeParser\n",
    "from docling.chunking import HybridChunker\n",
    "from pathlib import Path\n",
    "\n",
    "persist_dir = \"YOUR_HOME_DIR/datasets/persistent_vector_store\"\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=str(Path(\"YOUR_HOME_DIR/datasets/docling_md_vectordb.db\")),\n",
    "    dim=embed_dim,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=persist_dir),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(persist_dir=persist_dir),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=persist_dir),\n",
    ")\n",
    "\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98cfe7-1145-487a-9406-053a07a5bf11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "def generate_response(question, model_name=\"qwen-32b-COT\"):\n",
    "    retrieved_docs = retriever.retrieve(question)\n",
    "    print(f\"Retrieved {len(retrieved_docs)} docs\")\n",
    "    sources = [s.get_content(s.metadata) for s in retrieved_docs]\n",
    "    sourcesStr = \"\\n\\n\".join(sources)\n",
    "    \n",
    "    QUERY = f\"### Input:\\n{question}\\nContext:\\n{sourcesStr}\\n\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": QUERY,\n",
    "        \"stream\": True,\n",
    "        \"options\": {\"num_predict\":1000}\n",
    "    }\n",
    "    url = \"http://leinewra100.mh-hannover.local:11434/api/generate\"\n",
    "    #for i in range(5):\n",
    "    #    try:\n",
    "    response = requests.post(url, json=data, timeout=120)\n",
    "    con_text = \"\"\n",
    "    for l in response.text.split(\"\\n\"):\n",
    "        try:\n",
    "            obj = json.loads(l)\n",
    "        except:\n",
    "            #print(f\"Failed at '{l}'\")\n",
    "            continue    \n",
    "        if \"done\" in obj:\n",
    "            if obj[\"done\"] == True:\n",
    "                text = con_text\n",
    "            else:\n",
    "                con_text += obj[\"response\"]\n",
    "    #        break\n",
    "    #    except:\n",
    "    #        print(f\"Errored {i}\")\n",
    "    return text, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a55c1-8c7c-4f60-8a8d-8a44f2abc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedModel = \"meditron:7b-fp16\"\n",
    "usedDataset = \"deepseek_COT_raft\"\n",
    "savePath = f\"YOUR_HOME_DIR/datasets/evaluation/{usedDataset}/{usedModel.replace(':', '-').replace('/', '-')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75643c-7b4c-47a4-90a9-49f770004ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyarrow.parquet import ParquetDataset\n",
    "import time\n",
    "dataset = ParquetDataset(f\"YOUR_HOME_DIR/datasets/{usedDataset}/val.parquet\")\n",
    "pds = dataset.read().to_pandas()\n",
    "\n",
    "test_cases = []\n",
    "for idx, row in pds.iterrows():\n",
    "    d = row.to_dict()\n",
    "    question = d[\"question\"]\n",
    "    output = d[\"answer\"]\n",
    "    try:\n",
    "        generated_output, used_sources = generate_response(question, model_name=usedModel)\n",
    "        case = {}\n",
    "        case[\"input\"] = question\n",
    "        case[\"expected_output\"] = output\n",
    "        case[\"actual_output\"] = generated_output\n",
    "        case[\"retrieval_context\"] = used_sources\n",
    "        test_cases.append(case)\n",
    "    except Exception as e:\n",
    "        print(\"error at \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502b50c-2beb-47bd-9880-af7b583f6a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Saving to {savePath}\")\n",
    "\n",
    "for e in test_cases:\n",
    "    for k in e.keys():\n",
    "        print(k)\n",
    "        print(e[k])\n",
    "    print(\"#\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84696a6e-91b7-4e5a-ba16-d007699993b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def saveDS():\n",
    "    for tc in test_cases:\n",
    "        yield tc\n",
    "\n",
    "tc_dataset = Dataset.from_generator(saveDS)\n",
    "tc_dataset.save_to_disk(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abb698-15ac-4bd9-8b74-e36126a55522",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2018f51-e365-41a4-8e8f-99bc517f7822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
