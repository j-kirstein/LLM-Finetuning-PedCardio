{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dc1be-f42f-4a02-a1b7-cc8aa2ae3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = \"HUGGINGFACE TOKEN HERE\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=hf_token\n",
    "os.environ[\"HF_TOKEN\"]=hf_token\n",
    "os.environ['HF_HOME'] = 'YOUR_HOME_DIR/.cache/huggingface/'\n",
    "os.environ['TRANSFOMERS_CACHE'] = 'YOUR_HOME_DIR/.cache/huggingface/'\n",
    "import transformers\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf88d1-021f-45c2-b792-b88da9d704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"llama31-8b-noCOT\", request_timeout=300.0)\n",
    "\n",
    "EMBED_MODEL = HuggingFaceEmbedding(model_name=\"abhinand/MedEmbed-large-v0.1\")\n",
    "\n",
    "#Settings.llm = llm\n",
    "Settings.embed_model = EMBED_MODEL\n",
    "embed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c287e8-44f3-4a07-ba5a-698cd45795d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD VECTORE INDEX FROM DISK (NOT WORKING PROPERLY)\n",
    "\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, load_index_from_storage\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from docling.document_converter import DocumentConverter\n",
    "from llama_index.node_parser.docling import DoclingNodeParser\n",
    "from docling.chunking import HybridChunker\n",
    "from pathlib import Path\n",
    "\n",
    "persist_dir = \"YOUR_HOME_DIR/datasets/persistent_vector_store\"\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=str(Path(\"YOUR_HOME_DIR/datasets/docling_md_vectordb.db\")),\n",
    "    dim=embed_dim,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=persist_dir),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(persist_dir=persist_dir),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=persist_dir),\n",
    ")\n",
    "\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ed85e-cc50-4470-adbe-ef072d1c8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AD HOC CREATION OF VECTOR INDEX (WORKS BUT IS SLOWER)\n",
    "\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from docling.document_converter import DocumentConverter\n",
    "from llama_index.node_parser.docling import DoclingNodeParser\n",
    "from docling.chunking import HybridChunker\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE = r\"YOUR_HOME_DIR/guideline_edit.md\"\n",
    "\n",
    "reader = DoclingReader()\n",
    "node_parser = MarkdownNodeParser()\n",
    "chunker = HybridChunker()\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=str(Path(\"YOUR_HOME_DIR/datasets/docling_md_vectordb_infer.db\")),\n",
    "    dim=embed_dim,\n",
    "    overwrite=True,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=reader.load_data(SOURCE),\n",
    "    transformations=[node_parser],\n",
    "    storage_context=storage_context,\n",
    "    embed_model=EMBED_MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98cfe7-1145-487a-9406-053a07a5bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "question = \"What is Pulmonary Atresia with Intact Ventricular Septum (PA-IVS) and what are its key morphological characteristics?\"\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "retrieved_docs = retriever.retrieve(question)\n",
    "print(f\"Retrieved {len(retrieved_docs)} docs\")\n",
    "sources = [s.get_content(s.metadata) for s in retrieved_docs]\n",
    "sourcesStr = \"\\n\\n\".join(sources)\n",
    "\n",
    "print(\"Sources:\")\n",
    "print(sourcesStr)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "QUERY = f\"### Input:\\n{question}\\nContext:\\n{sourcesStr}\\n\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"qwen-32b-COT\",\n",
    "    \"prompt\": QUERY,\n",
    "    \"stream\": False\n",
    "}\n",
    "url = \"http://leinewr011.mh-hannover.local:11434/api/generate\"\n",
    "response = requests.post(url, json=data, timeout=60*60*1000)\n",
    "text = response.json()[\"response\"]\n",
    "answer = text\n",
    "\n",
    "print(f\"\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75643c-7b4c-47a4-90a9-49f770004ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
