{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa8ba1-00fa-48b8-9a18-9d8b0582d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = \"HUGGINGFACE TOKEN HERE\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=hf_token\n",
    "os.environ[\"HF_TOKEN\"]=hf_token\n",
    "os.environ['HF_HOME'] = 'YOUR_HOME_DIR/.cache/huggingface/'\n",
    "os.environ['TRANSFOMERS_CACHE'] = 'YOUR_HOME_DIR/.cache/huggingface/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b1d50-00b7-4183-b1be-b48d653982a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def remove_thoughts_section(text):\n",
    "    return flatten([e.split(\"</think>\") for e in text.split(\"</thoughts>\")])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398789b-5460-489c-8045-925fb99f464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.scorer import Scorer\n",
    "import statistics\n",
    "\n",
    "usedDataset = \"deepseek_COT_raft\"\n",
    "dsBaseDir = f\"YOUR_HOME_DIR/datasets/evaluation/{usedDataset}/\"\n",
    "\n",
    "models = [f for f in os.listdir(dsBaseDir)]\n",
    "\n",
    "allResults = {}\n",
    "\n",
    "for usedModel in models:\n",
    "    print(\"Calculating BERTScore for \", usedModel)\n",
    "    datasetDir = dsBaseDir + usedModel\n",
    "    \n",
    "    ds = Dataset.load_from_disk(datasetDir)\n",
    "    \n",
    "    scorer = Scorer()\n",
    "    results = {}\n",
    "    data = []\n",
    "    for e in ds:\n",
    "        bertScore = scorer.bert_score(\n",
    "            references=remove_thoughts_section(e[\"expected_output\"]),\n",
    "            predictions=remove_thoughts_section(e[\"actual_output\"]),\n",
    "            #model=\"microsoft/deberta-xlarge-mnli\"\n",
    "        )\n",
    "        data.append(bertScore)\n",
    "        for k in bertScore.keys():\n",
    "            if k not in results.keys():\n",
    "                results[k] = []\n",
    "            results[k] = results[k] + bertScore[k]\n",
    "    \n",
    "    for k in results.keys():\n",
    "        print(f\"{k}: {statistics.fmean(results[k])}\")\n",
    "\n",
    "    allResults[usedModel] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefaa7ee-7721-4453-b6b5-2ef5d1d048a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llama31-advDS-COT\n",
    "#bert-precision: 0.35718521179289237\n",
    "#bert-recall: 0.2912410410235123\n",
    "#bert-f1: 0.32043151276148096\n",
    "\n",
    "#meditron-7b-COT\n",
    "#bert-precision: 0.29772718418009425\n",
    "#bert-recall: 0.1973740966344366\n",
    "#bert-f1: 0.24325300633375133\n",
    "\n",
    "#qwen-32b-COT-q4_K_M\n",
    "#bert-precision: 0.25752965741011563\n",
    "#bert-recall: 0.32418028234827273\n",
    "#bert-f1: 0.29016731679439545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63638bb-f400-4dde-a3c2-c6d0f109a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAverages = {model:{k:statistics.fmean(allResults[model][k]) for k in allResults[model].keys()} for model in allResults.keys()}\n",
    "print(allAverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94768469-1433-4a36-9e75-aa19eed62112",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAverages = {'meditron-7b-COT': {'bert-precision': 0.3047684439058815, 'bert-recall': 0.21074126485488093, 'bert-f1': 0.2503270188688624}, 'qwen-32b-basicDS': {'bert-precision': 0.4318103810810313, 'bert-recall': 0.12030459529416142, 'bert-f1': 0.2454918550745565}, 'meditron-7b-fp16': {'bert-precision': 0.03413265044515838, 'bert-recall': -0.021827182580469822, 'bert-f1': -0.003499159099990312}, 'meditron-7b-basicDS': {'bert-precision': 0.4151772189961404, 'bert-recall': 0.03516647587435282, 'bert-f1': 0.1870286071064825}, 'llama31-basicDS': {'bert-precision': 0.4348166682282273, 'bert-recall': 0.035279964039824446, 'bert-f1': 0.1904552257382216}, 'llama31-advDS-COT': {'bert-precision': 0.40585619758586494, 'bert-recall': 0.30333154602926604, 'bert-f1': 0.34611568417476146}, 'llama3.1-8b-instruct-fp16': {'bert-precision': 0.26908153483206976, 'bert-recall': 0.25759676277485427, 'bert-f1': 0.2573016523098459}, 'hengwen-DeepSeek-R1-Distill-Qwen-32B-q4_k_m': {'bert-precision': 0.1308120781821864, 'bert-recall': 0.26566630444781647, 'bert-f1': 0.18692373169338977}, 'qwen-32b-COT-q4_K_M': {'bert-precision': 0.11906920963119032, 'bert-recall': 0.3157404516728557, 'bert-f1': 0.20588080978439172}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42daf3-f46a-4b08-86af-d47a3ee7e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAverages[\"DeepSeek-R1-Distill-Qwen-32B\"] = allAverages[\"hengwen-DeepSeek-R1-Distill-Qwen-32B-q4_k_m\"]\n",
    "del allAverages[\"hengwen-DeepSeek-R1-Distill-Qwen-32B-q4_k_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c082a3-18df-4059-88fe-168ce132e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracting values\n",
    "models = ['llama3.1-8b-instruct-fp16', 'meditron-7b-fp16', 'DeepSeek-R1-Distill-Qwen-32B', 'llama31-basicDS', 'meditron-7b-basicDS', 'qwen-32b-basicDS', 'llama31-advDS-COT', 'meditron-7b-COT', 'qwen-32b-COT-q4_K_M']\n",
    "\n",
    "print(models)\n",
    "precision = [allAverages[m]['bert-precision'] for m in models]\n",
    "recall = [allAverages[m]['bert-recall'] for m in models]\n",
    "f1 = [allAverages[m]['bert-f1'] for m in models]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(x - width, precision, width, label='BERT Precision')\n",
    "ax.bar(x, recall, width, label='BERT Recall')\n",
    "ax.bar(x + width, f1, width, label='BERT F1 Score')\n",
    "\n",
    "additionalY = 0.465\n",
    "ax.axvline(x = 2.5, color = '0.5')\n",
    "ax.axvline(x = 5.5, color = '0.5')\n",
    "\n",
    "ax.text((-0.5 + 2.5)/3, additionalY, 'Base Models', style='italic', bbox={'facecolor': '0.8', 'alpha': 0.5, 'pad': 5})\n",
    "ax.text((-1 + 2.5)/3 + 3, additionalY, 'Basic Dataset Models', style='italic', bbox={'facecolor': '0.8', 'alpha': 0.5, 'pad': 5})\n",
    "ax.text((-1 + 2.5)/3 + 6, additionalY, 'Advanced Dataset Models', style='italic', bbox={'facecolor': '0.8', 'alpha': 0.5, 'pad': 5})\n",
    "\n",
    "# Labels & Titles\n",
    "ax.set_xlabel(\"Models\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"BERTScores for Different Models\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "ax.set_ylim(-0.05, 0.56)\n",
    "\n",
    "\n",
    "# Create a break in the y-axis\n",
    "ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.55])\n",
    "ax.set_yticklabels([\"0\", \"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"1\"])\n",
    "ax.spines['top'].set_visible(False)\n",
    "# Add a break indicator (zigzag lines)\n",
    "#ax.plot([-0.5, 8.75], [0.55, 0.55], \"k--\", lw=1)\n",
    "#ax.plot([-0.5, 8.75], [0.5, 0.5], \"k--\", lw=1)\n",
    "ax.axhline(y = 0.55, color = '0.5', linestyle=\"--\")\n",
    "ax.axhline(y = 0.5, color = '0.5', linestyle=\"--\")\n",
    "\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"YOUR_HOME_DIR/datasets/evaluation/deepseek_COT_raft/BERTScore_allModels.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266008c3-ed5e-4cfa-95eb-0e1dfe99ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data.sort(key=lambda x: x[\"bert-f1\"])\n",
    "\n",
    "# Extract sorted values\n",
    "precision = [d[\"bert-precision\"][0] for d in data]\n",
    "recall = [d[\"bert-recall\"][0] for d in data]\n",
    "f1 = [d[\"bert-f1\"][0] for d in data]\n",
    "\n",
    "# Number of groups\n",
    "n = len(data)\n",
    "\n",
    "# X locations for the bars\n",
    "x = np.arange(n)\n",
    "\n",
    "# Bar width\n",
    "width = 0.25  \n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(x + width, f1, width, label=\"F1-score\", color='r', alpha=0.7)\n",
    "plt.bar(x, precision, width, label=\"Precision\", color='b', alpha=0.7)\n",
    "plt.bar(x - width, recall, width, label=\"Recall\", color='y', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Entries (Sorted by F1-score)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"BERT Precision, Recall, and F1-score\")\n",
    "plt.xticks(x, [str(i) for i in range(n)], rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea564c-c5a5-488d-a15d-001a85388c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds[0]\n",
    "print(\"Input\")\n",
    "print(test[\"input\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"expected_output\")\n",
    "print(remove_thoughts_section(test[\"expected_output\"]))\n",
    "print(\"\\n\\n\")\n",
    "print(\"actual_output\")\n",
    "print(remove_thoughts_section(test[\"actual_output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270aeb-d9c4-4da4-a392-1e5366a8de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
